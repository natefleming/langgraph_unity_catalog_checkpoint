{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async Unity Catalog Checkpointer Example\n",
    "\n",
    "This notebook demonstrates how to use the `AsyncUnityCatalogCheckpointSaver` for asynchronous graph execution with Unity Catalog persistence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets for configuration\n",
    "dbutils.widgets.text(\"catalog\", \"\", \"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema\", \"\", \"Schema Name\")\n",
    "dbutils.widgets.text(\"warehouse_id\", \"\", \"Warehouse ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src directory to Python path for custom code imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable nested async support for Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "print(\"✓ Nested asyncio support enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import Annotated\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langgraph_unity_catalog_checkpoint import AsyncUnityCatalogCheckpointSaver\n",
    "\n",
    "# Initialize Databricks WorkspaceClient\n",
    "workspace_client: WorkspaceClient = WorkspaceClient()\n",
    "\n",
    "# Initialize ChatDatabricks with Llama model\n",
    "llm: ChatDatabricks = ChatDatabricks(endpoint=\"databricks-meta-llama-3-3-70b-instruct\")\n",
    "\n",
    "# Configuration for Unity Catalog - prefer environment variables over widgets\n",
    "catalog: str = os.getenv(\"UC_CATALOG\") or dbutils.widgets.get(\"catalog\")\n",
    "schema: str = os.getenv(\"UC_SCHEMA\") or dbutils.widgets.get(\"schema\")\n",
    "warehouse_id: str | None = os.getenv(\"DATABRICKS_WAREHOUSE_ID\") or dbutils.widgets.get(\"warehouse_id\") or None\n",
    "\n",
    "print(f\"Using catalog: {catalog}\")\n",
    "print(f\"Using schema: {schema}\")\n",
    "print(f\"Using warehouse_id: {warehouse_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MLflow autologging for LangChain\n",
    "import mlflow\n",
    "mlflow.langchain.autolog()\n",
    "print(\"✓ MLflow LangChain autologging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Catalog and Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create catalog if it doesn't exist using Catalog API\n",
    "try:\n",
    "    workspace_client.catalogs.create(name=catalog, comment=\"Unity Catalog for LangGraph persistence\")\n",
    "    print(f\"✓ Created catalog '{catalog}'\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"✓ Catalog '{catalog}' already exists\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not create catalog: {e}\")\n",
    "\n",
    "# Create schema if it doesn't exist using Schema API\n",
    "try:\n",
    "    workspace_client.schemas.create(\n",
    "        name=schema,\n",
    "        catalog_name=catalog,\n",
    "        comment=\"Schema for LangGraph checkpoints and stores\"\n",
    "    )\n",
    "    print(f\"✓ Created schema '{catalog}.{schema}'\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"✓ Schema '{catalog}.{schema}' already exists\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not create schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Async Graph State and Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state schema\n",
    "class State(TypedDict):\n",
    "    \"\"\"State for the agent graph.\"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Define async chatbot node\n",
    "async def chatbot(state: State) -> dict[str, list[BaseMessage]]:\n",
    "    \"\"\"Async chatbot node that uses Databricks LLM.\"\"\"\n",
    "    response: BaseMessage = await llm.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Async Checkpointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the async checkpointer with default table names\n",
    "# Default tables follow PostgreSQL/LangGraph conventions:\n",
    "# - checkpoints_table: \"checkpoints\"\n",
    "# - checkpoint_blobs_table: \"checkpoint_blobs\"\n",
    "# - writes_table: \"checkpoint_writes\"\n",
    "checkpointer = AsyncUnityCatalogCheckpointSaver(\n",
    "    workspace_client=workspace_client,\n",
    "    catalog=catalog,\n",
    "    schema=schema,\n",
    "    warehouse_id=warehouse_id,\n",
    ")\n",
    "\n",
    "print(f\"✓ Async checkpointer created\")\n",
    "print(f\"  Checkpoints table: {checkpointer.full_checkpoints_table}\")\n",
    "print(f\"  Writes table: {checkpointer.full_writes_table}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Compile the Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile with async checkpointer\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"✓ Graph compiled with async checkpoint persistence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Execution - First Interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"async_conversation_1\"}}\n",
    "\n",
    "# First async interaction\n",
    "print(\"First async interaction:\")\n",
    "result = await graph.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the capital of France?\")]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Response: {result['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Async Interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second async interaction\n",
    "print(\"Second async interaction:\")\n",
    "result = await graph.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What was my last question to you?\")]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Response: {result['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Async Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream results asynchronously\n",
    "print(\"Streaming responses:\")\n",
    "async for event in graph.astream(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me a joke\")]},\n",
    "    config=config\n",
    "):\n",
    "    if \"chatbot\" in event:\n",
    "        print(f\"Chatbot: {event['chatbot']['messages'][0].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Conversation History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the full conversation history\n",
    "print(\"\\nFull conversation history:\")\n",
    "state = await graph.aget_state(config)\n",
    "for msg in state.values[\"messages\"]:\n",
    "    msg_type = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"  {msg_type}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Checkpoints Asynchronously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List checkpoints asynchronously\n",
    "print(\"\\nCheckpoints for this thread:\")\n",
    "i = 0\n",
    "async for checkpoint_tuple in checkpointer.alist(config):\n",
    "    i += 1\n",
    "    checkpoint_id = checkpoint_tuple.config[\"configurable\"][\"checkpoint_id\"]\n",
    "    metadata = checkpoint_tuple.metadata\n",
    "    print(f\"\\nCheckpoint {i}:\")\n",
    "    print(f\"  ID: {checkpoint_id}\")\n",
    "    print(f\"  Metadata: {metadata}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
