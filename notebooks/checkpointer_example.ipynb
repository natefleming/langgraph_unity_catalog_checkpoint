{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity Catalog Checkpointer Example\n",
    "\n",
    "This notebook demonstrates how to use the `UnityCatalogCheckpointSaver` to persist LangGraph state in Databricks Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets for configuration\n",
    "dbutils.widgets.text(\"catalog\", \"\", \"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema\", \"\", \"Schema Name\")\n",
    "dbutils.widgets.text(\"warehouse_id\", \"\", \"Warehouse ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src directory to Python path for custom code imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable nested async support for Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "print(\"✓ Nested asyncio support enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from langgraph_unity_catalog_checkpoint import UnityCatalogCheckpointSaver\n",
    "\n",
    "# Initialize Databricks WorkspaceClient\n",
    "workspace_client: WorkspaceClient = WorkspaceClient()\n",
    "\n",
    "# Configuration for Unity Catalog - prefer environment variables over widgets\n",
    "catalog: str = os.getenv(\"UC_CATALOG\") or dbutils.widgets.get(\"catalog\")\n",
    "schema: str = os.getenv(\"UC_SCHEMA\") or dbutils.widgets.get(\"schema\")\n",
    "warehouse_id: str | None = os.getenv(\"DATABRICKS_WAREHOUSE_ID\") or dbutils.widgets.get(\"warehouse_id\") or None\n",
    "\n",
    "print(f\"Using catalog: {catalog}\")\n",
    "print(f\"Using schema: {schema}\")\n",
    "print(f\"Using warehouse_id: {warehouse_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "# Initialize Databricks WorkspaceClient\n",
    "workspace_client: WorkspaceClient = WorkspaceClient()\n",
    "\n",
    "# Initialize ChatDatabricks with Llama model\n",
    "llm: ChatDatabricks = ChatDatabricks(endpoint=\"databricks-meta-llama-3-3-70b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MLflow autologging for LangChain\n",
    "import mlflow\n",
    "mlflow.langchain.autolog()\n",
    "print(\"✓ MLflow LangChain autologging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Catalog and Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create catalog if it doesn't exist using Catalog API\n",
    "try:\n",
    "    workspace_client.catalogs.create(name=catalog, comment=\"Unity Catalog for LangGraph persistence\")\n",
    "    print(f\"✓ Created catalog '{catalog}'\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"✓ Catalog '{catalog}' already exists\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not create catalog: {e}\")\n",
    "\n",
    "# Create schema if it doesn't exist using Schema API\n",
    "try:\n",
    "    workspace_client.schemas.create(\n",
    "        name=schema,\n",
    "        catalog_name=catalog,\n",
    "        comment=\"Schema for LangGraph checkpoints and stores\"\n",
    "    )\n",
    "    print(f\"✓ Created schema '{catalog}.{schema}'\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"✓ Schema '{catalog}.{schema}' already exists\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not create schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Graph State and Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state schema\n",
    "class State(TypedDict):\n",
    "    \"\"\"State for the agent graph.\"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Define the chatbot node\n",
    "def chatbot(state: State) -> dict[str, list[BaseMessage]]:\n",
    "    \"\"\"Chatbot node that uses Databricks LLM.\"\"\"\n",
    "    response: BaseMessage = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Checkpointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the checkpointer with default table names\n",
    "# Default tables follow PostgreSQL/LangGraph conventions:\n",
    "# - checkpoints_table: \"checkpoints\"\n",
    "# - checkpoint_blobs_table: \"checkpoint_blobs\"\n",
    "# - writes_table: \"checkpoint_writes\"\n",
    "checkpointer = UnityCatalogCheckpointSaver(\n",
    "    workspace_client=workspace_client,\n",
    "    catalog=catalog,\n",
    "    schema=schema,\n",
    "    warehouse_id=warehouse_id,\n",
    ")\n",
    "\n",
    "print(f\"✓ Checkpointer created\")\n",
    "print(f\"  Checkpoints table: {checkpointer.full_checkpoints_table}\")\n",
    "print(f\"  Writes table: {checkpointer.full_writes_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile with checkpointer for persistence\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"✓ Graph compiled with checkpoint persistence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Conversation - First Interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"conversation_1\"}}\n",
    "\n",
    "# First interaction\n",
    "print(\"First interaction:\")\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hello, my name is Alice\")]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Response: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Interaction - State is Preserved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second interaction - graph remembers context from the same thread\n",
    "print(\"Second interaction:\")\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's my name?\")]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Response: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Conversation History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the conversation history\n",
    "print(\"Conversation history:\")\n",
    "state = await graph.aget_state(config)\n",
    "for msg in state.values[\"messages\"]:\n",
    "    msg_type = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"  {msg_type}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Checkpoints for This Thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all checkpoints for this thread\n",
    "print(\"\\nCheckpoints for this thread:\")\n",
    "for i, checkpoint_tuple in enumerate(checkpointer.list(config), 1):\n",
    "    checkpoint_id = checkpoint_tuple.config[\"configurable\"][\"checkpoint_id\"]\n",
    "    metadata = checkpoint_tuple.metadata\n",
    "    print(f\"\\nCheckpoint {i}:\")\n",
    "    print(f\"  ID: {checkpoint_id}\")\n",
    "    print(f\"  Metadata: {metadata}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
